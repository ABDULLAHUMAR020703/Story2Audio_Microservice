# ðŸŽ§ Story2Audio

**Story2Audio** is a multi-modal AI storytelling system that takes a short prompt and generates a complete narrated story with expressive emotional audio. It uses a custom gRPC backend powered by LLaMA3 (via Ollama), XTTS (voice cloning), and Streamlit or REST clients to provide a responsive and flexible frontend experience.

---

## ðŸ§  Architecture

```
User (Streamlit or REST)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         gRPC Server                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ - Story prompt + meta   â”‚            â”‚
â”‚  â”‚ - LLaMA3/Mistral LLM    â”‚            â”‚
â”‚  â”‚ - XTTS for voice TTS    â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
ðŸŽ§ Audio Output + ðŸ“œ Story Text
```

---

## âš™ï¸ Set Up Environment

```bash
# 1. Clone the repository
git clone https://github.com/yourusername/story2audio.git
cd story2audio

# 2. Create a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Prepare model directories
mkdir -p output voices xtts_model
```

> âœ… Make sure you have:
>
> * A CUDA-compatible GPU (for XTTS)
> * `ollama` installed and running locally (`ollama pull llama3` and `ollama pull mistral:7b-instruct`)
> * XTTS model files inside `xtts_model/` directory
> * Protocol buffers compiler installed for gRPC

---

## ðŸš€ Running the Service

### Start the gRPC server
```bash
python server.py
```

### Start the Streamlit frontend
```bash
streamlit run streamlit_ms.py
```

### (Optional) Start the REST proxy server
```bash
python rest_server.py
```
This will start a REST server at `http://localhost:8000/generate-story/`.

---

## ðŸ“± gRPC Interface

### Proto file: `story_service.proto`
```proto
syntax = "proto3";

service StoryService {
  rpc GenerateStory (StoryRequest) returns (StoryResponse);
}

message StoryRequest {
  string prompt = 1;
  string emotion = 2;
  float speed = 3;
  string language = 4;
  string speaker_audio = 5;
  bool include_narration = 6;
}

message StoryResponse {
  bytes audio = 1;
  string text = 2;
  string message = 3;
}
```

---

## âœ¨ Features

* ðŸ“œ **Intelligent Story Generation**: Create compelling stories with LLaMA3 or Mistral based on your prompt and desired length
* ðŸŽ­ **Emotional Expression**: Choose from different emotional tones (happy, sad, angry, neutral)
* ðŸ—£ï¸ **Voice Modes**: Select between narration-only or narration + dialogue (with female character voices)
* ðŸŒ **Multi-language Support**: Generate stories in multiple languages (en, es, fr, de, hi, it, ru)
* ðŸ”Š **Voice Cloning**: Use any voice by uploading a .wav file (â‰¥15s) or recording directly in the app
* âš¡ **Concurrent Processing**: Generate multiple stories simultaneously with real-time progress tracking
* ðŸŽ›ï¸ **Customization Options**: Adjust speech speed and story complexity to your preferences

---

## ðŸ—£ï¸ How to Add Custom Voice

In the Streamlit interface:
1. Upload a `.wav` file (minimum 15 seconds)
2. OR record your voice using the built-in microphone recorder
3. Provide a unique speaker name
4. Your voice will appear in the dropdown menu for future story generation

All voices are saved under the `voices/` folder and indexed in `speakers.json`.

---

## ðŸŒ REST API Usage

### Endpoint:
```
POST http://localhost:8000/generate-story/
```

### JSON Payload:
```json
{
  "prompt": "[PARA_LEVEL:1â€“3] A young girl finds a lost puppy in the rain.",
  "emotion": "happy",
  "speed": 1.0,
  "language": "en",
  "include_narration": true,
  "speaker_audio_base64": "Uk1GR..."
}
```

### Response:
```json
{
  "text": "Generated story text...",
  "message": "success",
  "audio_file": "response_audio.wav"
}
```

---

## ðŸ§ª Test Case Format & Automation

Sample test case format (`TestCases.json`):
```json
[
  {
    "prompt": "[PARA_LEVEL:1â€“3] A young girl finds a lost puppy in the rain.",
    "emotion": "happy",
    "speed": 1.0,
    "language": "en",
    "include_narration": true,
    "speaker_audio_base64": "Uk1GR..."
  }
]
```

You can use this with `rest_server.py` to send batches of test prompts to the gRPC server via REST.

---

## ðŸ“Š Performance Evaluation

The graph below shows the average response time based on story length and voice mode:

![Average Response Time vs. Paragraph Range](./performance_graph.png)


| Paragraph Range | Narration Only | Narration + Dialogue |
|-----------------|---------------:|---------------------:|
| 1-3 paragraphs  | ~1.8 minutes   | ~2.8 minutes         |
| 4-7 paragraphs  | ~7.0 minutes   | ~9.0 minutes         |
| 8+ paragraphs   | ~8.0 minutes   | ~9.9 minutes         |

Key observations:
- Narration + Dialogue mode takes approximately 20-30% longer than Narration Only
- Processing time increases significantly between short (1-3) and medium (4-7) stories
- Response times are based on a system with NVIDIA RTX 3050 GPU

---

> â„¹ï¸ **Tips for Best Results**:  
> * Prompt must be in English â€” this works best for generating English audio stories  
> * Use specific, emotionally rich story prompts  
> * Choose a voice and emotion that match your story theme  
> * For longer stories, use `[PARA_LEVEL:8+]` in your prompt  
> * High-quality speaker audio (clear, minimal background noise) improves speaker cloning  
> * Longer paragraph levels take more time to process; shorter ones are faster  
> * Ensure GPU is enabled for faster processing


## ðŸ‘¥ Contributors
- Hasnain Ibrar Butt (https://github.com/Hasnain2430))
- Abdullah Bin Umar (https://github.com/ABDULLAHUMAR020703)

